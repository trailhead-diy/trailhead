/**
 * Performance Utilities
 * 
 * Advanced utilities for performance monitoring and optimization
 */

export interface PerformanceMetrics {
  startTime: number
  endTime?: number
  duration?: number
  memoryUsage?: NodeJS.MemoryUsage
  operationName: string
}

export class PerformanceTracker {
  private metrics: Map<string, PerformanceMetrics> = new Map()
  
  /**
   * Start tracking performance for an operation
   */
  start(operationName: string): void {
    this.metrics.set(operationName, {
      operationName,
      startTime: performance.now(),
      memoryUsage: process.memoryUsage()
    })
  }
  
  /**
   * Stop tracking and get metrics
   */
  stop(operationName: string): PerformanceMetrics | null {
    const metric = this.metrics.get(operationName)
    if (!metric) {
      return null
    }
    
    const endTime = performance.now()
    const finalMetric: PerformanceMetrics = {
      ...metric,
      endTime,
      duration: endTime - metric.startTime
    }
    
    this.metrics.set(operationName, finalMetric)
    return finalMetric
  }
  
  /**
   * Get all recorded metrics
   */
  getAllMetrics(): PerformanceMetrics[] {
    return Array.from(this.metrics.values())
  }
  
  /**
   * Clear all metrics
   */
  clear(): void {
    this.metrics.clear()
  }
  
  /**
   * Get a summary report
   */
  getReport(): string {
    const metrics = this.getAllMetrics()
    if (metrics.length === 0) {
      return 'No performance metrics recorded'
    }
    
    let report = 'Performance Report:\n'
    report += '================\n\n'
    
    for (const metric of metrics) {
      report += `Operation: ${metric.operationName}\n`
      if (metric.duration !== undefined) {
        report += `Duration: ${metric.duration.toFixed(2)}ms\n`
      }
      if (metric.memoryUsage) {
        report += `Memory: ${(metric.memoryUsage.heapUsed / 1024 / 1024).toFixed(2)}MB\n`
      }
      report += '\n'
    }
    
    return report
  }
}

/**
 * Decorator for automatic performance tracking
 */
export function trackPerformance(operationName?: string) {
  return function (target: any, propertyKey: string, descriptor: PropertyDescriptor) {
    const originalMethod = descriptor.value
    const tracker = new PerformanceTracker()
    
    descriptor.value = async function (...args: any[]) {
      const opName = operationName || `${target.constructor.name}.${propertyKey}`
      
      tracker.start(opName)
      try {
        const result = await originalMethod.apply(this, args)
        const metrics = tracker.stop(opName)
        
        if (process.env.NODE_ENV === 'development' && metrics) {
          console.log(`âš¡ ${opName}: ${metrics.duration?.toFixed(2)}ms`)
        }
        
        return result
      } catch (error) {
        tracker.stop(opName)
        throw error
      }
    }
    
    return descriptor
  }
}

/**
 * Simple cache implementation for expensive operations
 */
export class SimpleCache<T> {
  private cache = new Map<string, { value: T; expiry: number }>()
  private defaultTTL: number
  
  constructor(defaultTTLMs = 300000) { // 5 minutes default
    this.defaultTTL = defaultTTLMs
  }
  
  get(key: string): T | undefined {
    const item = this.cache.get(key)
    if (!item) {
      return undefined
    }
    
    if (Date.now() > item.expiry) {
      this.cache.delete(key)
      return undefined
    }
    
    return item.value
  }
  
  set(key: string, value: T, ttlMs?: number): void {
    const expiry = Date.now() + (ttlMs || this.defaultTTL)
    this.cache.set(key, { value, expiry })
  }
  
  has(key: string): boolean {
    return this.get(key) !== undefined
  }
  
  delete(key: string): boolean {
    return this.cache.delete(key)
  }
  
  clear(): void {
    this.cache.clear()
  }
  
  size(): number {
    // Clean expired items first
    const now = Date.now()
    for (const [key, item] of this.cache.entries()) {
      if (now > item.expiry) {
        this.cache.delete(key)
      }
    }
    return this.cache.size
  }
}

/**
 * Utility for batching operations
 */
export class BatchProcessor<T, R> {
  private batch: T[] = []
  private processor: (items: T[]) => Promise<R[]>
  private batchSize: number
  private timeout: number
  private timer?: NodeJS.Timeout
  
  constructor(
    processor: (items: T[]) => Promise<R[]>,
    batchSize = 10,
    timeoutMs = 1000
  ) {
    this.processor = processor
    this.batchSize = batchSize
    this.timeout = timeoutMs
  }
  
  add(item: T): Promise<R> {
    return new Promise((resolve, reject) => {
      this.batch.push(item)
      
      // Store resolver for this item
      const itemIndex = this.batch.length - 1
      const originalResolve = resolve
      const originalReject = reject
      
      // Process immediately if batch is full
      if (this.batch.length >= this.batchSize) {
        this.processBatch().then(results => {
          originalResolve(results[itemIndex])
        }).catch(originalReject)
        return
      }
      
      // Set timeout for batch processing
      if (this.timer) {
        clearTimeout(this.timer)
      }
      
      this.timer = setTimeout(() => {
        this.processBatch().then(results => {
          originalResolve(results[itemIndex])
        }).catch(originalReject)
      }, this.timeout)
    })
  }
  
  private async processBatch(): Promise<R[]> {
    if (this.batch.length === 0) {
      return []
    }
    
    const currentBatch = [...this.batch]
    this.batch = []
    
    if (this.timer) {
      clearTimeout(this.timer)
      this.timer = undefined
    }
    
    return this.processor(currentBatch)
  }
  
  async flush(): Promise<R[]> {
    return this.processBatch()
  }
}